{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from talib import MACD, MACDEXT, RSI, BBANDS, MACD, AROON, STOCHF, ATR, OBV, ADOSC, MINUS_DI, PLUS_DI, ADX, EMA, SMA\n",
    "from talib import LINEARREG, BETA, LINEARREG_INTERCEPT, LINEARREG_SLOPE, STDDEV, TSF, ADOSC, VAR, ROC\n",
    "from talib import CDLABANDONEDBABY, CDL3BLACKCROWS,CDLDOJI, CDLDOJISTAR, CDLDRAGONFLYDOJI,CDLENGULFING,CDLEVENINGDOJISTAR,CDLEVENINGSTAR, CDLGRAVESTONEDOJI, CDLHAMMER, CDLHANGINGMAN,CDLHARAMI,CDLHARAMICROSS,CDLINVERTEDHAMMER,CDLMARUBOZU,CDLMORNINGDOJISTAR,CDLMORNINGSTAR,CDLSHOOTINGSTAR,CDLSPINNINGTOP,CDL3BLACKCROWS, CDL3LINESTRIKE, CDLKICKING\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tables\n",
    "import datetime as dt\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "from kiteconnect import KiteConnect\n",
    "from kiteconnect import KiteTicker\n",
    "import platform\n",
    "from selenium import webdriver\n",
    "import re\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import gc\n",
    "import warnings\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(filename=\"log/live_log.log\", filemode=\"a\", level=logging.DEBUG, format=\"[%(asctime)s: %(levelname)s]:%(message)s\") #format=\"[%(asctime)s: %(levelname)s]:%(message)s\"\n",
    "logger=logging.getLogger()\n",
    "#tradelogger=logger\n",
    "toTick = lambda x,n=5: np.round((np.floor(x *100)+n-1)/n)*n/100\n",
    "\n",
    "KiteAPIKey = \"b2w0sfnr1zr92nxm\"\n",
    "KiteAPISecret = \"jtga2mp2e5fn29h8w0pe2kb722g3dh1q\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty50 = pd.read_csv(\"data/ind_nifty50list.csv\")\n",
    "niftynext50 = pd.read_csv(\"data/ind_niftynext50list.csv\")\n",
    "midcap50 = pd.read_csv(\"data/ind_niftymidcap50list.csv\")\n",
    "\n",
    "downloadlist = nifty50['Symbol']\n",
    "industry = niftynext50['Industry'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday = pd.DataFrame([dt.datetime(2019,3,4),\n",
    "dt.datetime(2019,3,21),\n",
    "dt.datetime(2019,4,17),\n",
    "dt.datetime(2019,4,19),\n",
    "dt.datetime(2019,4,29),\n",
    "dt.datetime(2019,5,1),\n",
    "dt.datetime(2019,6,5),\n",
    "dt.datetime(2019,8,12),\n",
    "dt.datetime(2019,8,15),\n",
    "dt.datetime(2019,9,10)])\n",
    "\n",
    "\n",
    "isholiday = lambda mydt: ((holiday == mydt).any() == True)[0] or mydt.weekday() == 5 or mydt.weekday() == 6\n",
    "\n",
    "def getFromDate(todate,  days = 1):\n",
    "    tmp = todate.weekday()\n",
    "    if tmp == 0:\n",
    "        days = days + 2\n",
    "    elif tmp >4:\n",
    "        days = days + tmp - 5\n",
    "    \n",
    "    days = days + 1\n",
    "    \n",
    "    \n",
    "    fromdate = todate - dt.timedelta(days=days)\n",
    "    \n",
    "    adj = holiday[(holiday > fromdate)&(holiday<todate)].dropna().shape[0]\n",
    "    fromdate = fromdate - dt.timedelta(days=adj)\n",
    "    return fromdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicators and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"KiteConnect_Charting.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historical Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInstruments(exchange='NSE'):\n",
    "    instruments_df = pd.DataFrame(data=kite.instruments(exchange))\n",
    "    instruments_df = instruments_df.set_index('tradingsymbol')\n",
    "    return instruments_df\n",
    "\n",
    "def downloadData(symbol=\"HDFC\", fromDate= dt.datetime.now() - dt.timedelta(days = 1), toDate=dt.datetime.now(), freq=\"minute\"):\n",
    "    symbolToken = instruments_df.loc[symbol,'instrument_token']\n",
    "    \n",
    "    if type(symbolToken).__name__ == 'Series':\n",
    "        symbolToken = symbolToken[symbol].values[0]\n",
    "    \n",
    "    logging.debug(freq)\n",
    "    raw_data = pd.DataFrame(data=kite.historical_data(symbolToken, fromDate, toDate, freq, continuous=False))\n",
    "    raw_data = raw_data.set_index('date').tz_localize(None)\n",
    "    return raw_data\n",
    "\n",
    "def resample2(data,freq):\n",
    "    data = data.resample(freq).agg({'open':'first','high':'max','low':'min','close':'last','volume':'sum'})\n",
    "    #data.columns = data.columns.droplevel()\n",
    "    return data\n",
    "\n",
    "def getData(symbol, fromDate, toDate, exchange=\"NSE\", freq=\"minute\", force=False, symbolToken=''):\n",
    "    #symbol = \"SBIN\"\n",
    "    key = freq+\"/\"+exchange+\"/\"+symbol\n",
    "    \n",
    "    try:\n",
    "        if symbolToken == '':\n",
    "            symbolToken = instruments_df.loc[symbol,'instrument_token']\n",
    "    except:\n",
    "        logger.debug(symbol+\":stock not in the list\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    #fromDate = dt.datetime(2019,4,8)\n",
    "    #toDate = dt.datetime(2019,4,10)\n",
    "    \n",
    "    if force:\n",
    "        temp_data = downloadData(symbol, fromDate, toDate, freq)\n",
    "        return temp_data\n",
    "    \n",
    "    try:\n",
    "        temp_file = pd.HDFStore(\"kite_data/kite_cache.h5\", mode=\"r\")\n",
    "        rDate = temp_file.get(key).tail(1).index\n",
    "        lDate = temp_file.get(key).head(1).index\n",
    "        \n",
    "        temp_file.close()\n",
    "        \n",
    "        #print(fromDate,toDate, lDate, rDate)\n",
    "        raw_data = pd.read_hdf(\"kite_data/kite_cache.h5\", key=key, mode=\"r\", format=\"table\")\n",
    "\n",
    "        if   (fromDate < lDate ) and (toDate <= rDate):\n",
    "            logging.info(\"Downloading data from fromDate to lDate\")\n",
    "            temp_data = downloadData(symbol,  fromDate, lDate, freq)\n",
    "            temp_data = temp_data.append(raw_data.tail(-1))\n",
    "#            temp_data.to_hdf(\"kite_data/kite_cache.h5\", key=key, mode=\"a\", format=\"table\")\n",
    "        elif (fromDate >=lDate ) and (toDate <= rDate):\n",
    "            logging.info(\"Using cache: Not downloading data\")\n",
    "            temp_data = raw_data\n",
    "        elif (fromDate >= lDate ) and (toDate > rDate):\n",
    "            logging.info(\"Downloading data from rDate to toDate\")\n",
    "            temp_data = downloadData(symbol,  rDate, toDate, freq)\n",
    "            temp_data = raw_data.append(temp_data.tail(-1))\n",
    "#            temp_data.to_hdf(\"kite_data/kite_cache.h5\", key=key, mode=\"a\", format=\"table\")\n",
    "        elif (fromDate < lDate ) and (toDate > rDate):\n",
    "            logging.info(\"Downloading data from fromDate to lDate\")\n",
    "            temp_data = downloadData(symbol,  fromDate, lDate, freq)\n",
    "            temp_data = temp_data.append(raw_data.tail(-1))\n",
    "            logging.info(\"Downloading data from rDate to toDate\")\n",
    "            temp_data2 = downloadData(symbol,  rDate, toDate, freq)\n",
    "            temp_data = temp_data.append(temp_data2.tail(-1))\n",
    "#            temp_data.to_hdf(\"kite_data/kite_cache.h5\", key=key, mode=\"a\", format=\"table\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.debug(e)\n",
    "        temp_data = downloadData(symbol, fromDate, toDate, freq)\n",
    "    finally:\n",
    "        temp_data.to_hdf(\"kite_data/kite_cache.h5\", key=key, mode=\"a\", format=\"table\")\n",
    "        return temp_data[(temp_data.index >= fromDate) & (temp_data.index <= toDate)]\n",
    "    \n",
    "def portfolioDownload(stocklist, toDate):\n",
    "    stocklist_df = pd.DataFrame()\n",
    "    for index, row in stocklist.iterrows():\n",
    "        symbol = row[0]\n",
    "        logging.info(\"Downloading data for: \"+symbol)\n",
    "        temp_data = getData(symbol,  toDate - dt.timedelta(days = 5), toDate)\n",
    "        temp_data['symbol'] = symbol\n",
    "        temp_data.set_index(['symbol',temp_data.index], inplace=True)\n",
    "        #print(temp_data)\n",
    "        stocklist_df = stocklist_df.append(temp_data)\n",
    "    \n",
    "    #print(stocklist_df)\n",
    "    return stocklist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Kite Authentication and wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kite = KiteConnect(api_key=KiteAPIKey)\n",
    "reauthentication = False\n",
    "\n",
    "f = open(\"kite_data/access_token.txt\", mode=\"r\")\n",
    "access_token = f.readlines()\n",
    "logger.info(access_token[0])\n",
    "\n",
    "try:\n",
    "    kite.set_access_token(access_token[0])\n",
    "    logger.info(\"Welcome \"+kite.profile()['user_name'])\n",
    "except:\n",
    "    logger.critical(\"Offline Mode: Could not authenticate with the Kite Server\")\n",
    "    offline = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    if exchange==\"\":\n",
    "        exchange = \"NSE\"\n",
    "except:\n",
    "    logging.debug(\"Exchange not defined: Using default NSE\")\n",
    "    exchange = \"NSE\"\n",
    "\n",
    "try:\n",
    "    instruments_df = getInstruments(exchange)\n",
    "    instruments_df.to_hdf('kite_data/kite_cache.h5', key=exchange, mode='a', format=\"table\")\n",
    "except:\n",
    "    logger.critical(\"Error in downloading instrument table from kite\")\n",
    "    \n",
    "try:\n",
    "    instruments_df = pd.read_hdf('kite_data/kite_cache.h5', key=exchange, mode='r', format=\"table\")\n",
    "\n",
    "    EQSYMBOL = lambda x:instruments_df[instruments_df['instrument_token']==x].index[0]\n",
    "    EQTOKEN = lambda x:instruments_df.loc[x,'instrument_token']\n",
    "except:\n",
    "    logger.critical(\"Error in reading h5 file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Kite- Order Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#logging.critical(\"BUY\"+symbol)\n",
    "def buy_slm(symbol, price, trigger,quantity=1): \n",
    "    logger.info('%12s'%\"BUY SLM: \"+symbol+\", price: \"+str('%0.2f'%price)+\", stoploss: \"+str('%0.2f'%stoploss)+\", quantity: \"+str(quantity))\n",
    "    \n",
    "    if papertrade:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        order_id = kite.place_order(tradingsymbol=symbol,\n",
    "                                exchange=kite.EXCHANGE_NSE,\n",
    "                                transaction_type=kite.TRANSACTION_TYPE_BUY,\n",
    "                                quantity=quantity,\n",
    "                                order_type=kite.ORDER_TYPE_SLM,\n",
    "                                product=kite.PRODUCT_MIS,\n",
    "                                trigger_price=round(trigger,1),\n",
    "                                #stoploss=round(stoploss,1),\n",
    "                                #price=price,\n",
    "                                variety=kite.VARIETY_REGULAR\n",
    "                                )\n",
    "        logger.info(\"Order placed. ID is: {}\".format(order_id))\n",
    "    except Exception as e:\n",
    "        logger.info(\"Order placement failed: {}\".format(e.message))\n",
    "        \n",
    "def sell_slm(symbol, price, trigger, quantity=1):\n",
    "    \n",
    "    logger.info('%12s'%\"SELL SLM: \"+symbol+\", price: \"+str('%0.2f'%price)+\", stoploss: \"+str('%0.2f'%stoploss)+\", quantity: \"+str(quantity))\n",
    "       \n",
    "    if papertrade:\n",
    "         return\n",
    "    try:\n",
    "        order_id = kite.place_order(tradingsymbol=symbol,\n",
    "                            exchange=kite.EXCHANGE_NSE,\n",
    "                            transaction_type=kite.TRANSACTION_TYPE_SELL,\n",
    "                            quantity=quantity,\n",
    "                            order_type=kite.ORDER_TYPE_SLM,\n",
    "                            product=kite.PRODUCT_MIS,\n",
    "                            trigger_price=round(trigger,1),\n",
    "                            #price=price,\n",
    "                            variety=kite.VARIETY_REGULAR)\n",
    "        logger.info(\"Order placed. ID is: {}\".format(order_id))\n",
    "    except Exception as e:\n",
    "        logger.info(\"Order placement failed: {}\".format(e.message))\n",
    "\n",
    "def buy_bo(symbol, price, trigger, stoploss, squareoff, quantity=1, tag=\"bot\"): \n",
    "    logger.info('%12s'%\"BUY BO: \"+symbol+\", price: \"+str('%0.2f'%price)+\", squareoff: \"+str('%0.2f'%squareoff)+\", stoploss: \"+str('%0.2f'%stoploss)+\", quantity: \"+str(quantity))\n",
    "    if papertrade:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        order_id = kite.place_order(tradingsymbol=symbol, exchange=kite.EXCHANGE_NSE, transaction_type=kite.TRANSACTION_TYPE_BUY,\n",
    "                        order_type=kite.ORDER_TYPE_LIMIT, product=kite.PRODUCT_MIS, variety=kite.VARIETY_BO, \n",
    "                                quantity=quantity, trigger_price=trigger, price=price,\n",
    "                                squareoff=squareoff,  stoploss=stoploss, tag=tag )\n",
    "        logger.info(\"Order placed. ID is: {}\".format(order_id))\n",
    "    except Exception as e:\n",
    "        logger.info(\"Order placement failed: {}\".format(e.message))\n",
    "\n",
    "\n",
    "\n",
    "def sell_bo(symbol, price, trigger, stoploss, squareoff, quantity=1, tag=\"bot\"): \n",
    "    logger.info('%12s'%\"SELL BO: \"+symbol+\", price: \"+str('%0.2f'%price)+\", squareoff: \"+str('%0.2f'%squareoff)+\", stoploss: \"+str('%0.2f'%stoploss)+\", quantity: \"+str(quantity))\n",
    "    if papertrade:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        order_id = kite.place_order(tradingsymbol=symbol, exchange=kite.EXCHANGE_NSE, transaction_type=kite.TRANSACTION_TYPE_SELL,\n",
    "                                order_type=kite.ORDER_TYPE_LIMIT, product=kite.PRODUCT_MIS, variety=kite.VARIETY_BO,\n",
    "                                quantity=quantity, trigger_price=trigger, price=price,\n",
    "                                stoploss=stoploss, squareoff=squareoff,  tag=tag )\n",
    "        logger.info(\"Order placed. ID is: {}\".format(order_id))\n",
    "    except Exception as e:\n",
    "        logger.info(\"Order placement failed: {}\".format(e.message))\n",
    "        \n",
    "def getOrders():    \n",
    "    # Fetch all orders\n",
    "    return pd.DataFrame(kite.orders())\n",
    "\n",
    "def cancelOrder(orderId):\n",
    "    if papertrade:\n",
    "        logging.critical(\"In Paper Trade Mode: Order cancellation not possible\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        kite.cancel_order(variety=kite.VARIETY_REGULAR, order_id=orderId, parent_order_id=None)    \n",
    "    except Exception as e:\n",
    "        logger.info(\"Order Cancellation failed: {}\".format(e.message))\n",
    "        \n",
    "def squareoff(symbol=None, tag=\"bot\"):\n",
    "    logger.info('%12s'%\"Squareoff: \"+symbol)\n",
    "    if papertrade:\n",
    "        return\n",
    "    \n",
    "    orders_df = pd.DataFrame(kite.orders())\n",
    "    if symbol != None:\n",
    "        open_orders = orders_df[(orders_df['tradingsymbol']==symbol) & (orders_df['status'] == 'TRIGGER PENDING')  & (orders_df['tag'] == tag)]\n",
    "    else:\n",
    "        open_orders = orders_df[(orders_df['status'] == 'TRIGGER PENDING')  & (orders_df['tag'] == tag)]\n",
    "        \n",
    "    for index, row in open_orders.iterrows():\n",
    "        print(row.order_id, row.parent_order_id)\n",
    "        #kite.exit_order(variety=kite.VARIETY_AMO, order_id=row.order_id, parent_order_id=row.parent_order_id)\n",
    "        kite.exit_order(variety=kite.VARIETY_BO, order_id=order_id, parent_order_id=parent_order_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Kite - Live Tick Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def resample(ws, freq=\"1min\"):\n",
    "    #F = open(\"kite_data/recommendation.csv\",\"a\") \n",
    "    \n",
    "    logging.debug(str(ws.prevtimeStamp)+\": In resampler function\")\n",
    "    \n",
    "    if ws.LiveStream.empty:\n",
    "        logging.debug(str(ws.prevtimeStamp)+\": Empty dataframe, Exiting resampler\")\n",
    "        return\n",
    "      \n",
    "    LiveStream2 = ws.LiveStream.groupby(['symbol','date']).agg({'price':['first','max','min','last'], 'volume':['last']})\n",
    "    LiveStream2.columns = LiveStream2.columns.droplevel()\n",
    "    LiveStream2.columns = ['open', 'high','low','close', 'volume']\n",
    "\n",
    "    for index, data in LiveStream2.groupby(level=0):\n",
    "        sampled = data.loc[index].resample(freq).agg({'open':{'open':'first'},'high':{'high':'max'},'low':{'low':'min'},'close':{'close':'last'},'volume':{'volume':'last'}})\n",
    "        sampled.columns = sampled.columns.droplevel()\n",
    "        logger.debug(index)\n",
    "        \n",
    "        sampled['volume'] = sampled['volume'] - sampled['volume'].shift(1) \n",
    "        sampled['symbol'] = index\n",
    "        sampled.set_index(['symbol',sampled.index], inplace=True)\n",
    "        #logger.debug(sampled.tail())\n",
    "\n",
    "        ws.LiveStreamOHLC = ws.LiveStreamOHLC.append(sampled.iloc[-1])\n",
    "        \n",
    "    #ws.LiveStreamOHLC.to_csv(\"kite_data/livestreamohlc.csv\", mode='a')\n",
    "\n",
    "    for symbol in portfolio[0]:\n",
    "        #symbol = portfolio[0].iloc[-1]\n",
    "        temp_ohlc_df = ws.LiveStreamOHLC.loc[symbol].tail(120)\n",
    "        ws.tradebook_df.loc[symbol,'symbol'].trade_manager(symbol, temp_ohlc_df)\n",
    "    \n",
    "    \n",
    "def ticksHandler(ws, ticks):\n",
    "    #timeStamp = dt.datetime.now().replace(second=0, microsecond=0)\n",
    "    tick_df = pd.DataFrame(ticks)\n",
    "    \n",
    "    try:\n",
    "        #tick_df.loc[tick_df['timestamp'].isna(), 'timestamp'] = timeStamp\n",
    "        tick_df = tick_df[['timestamp','instrument_token','last_price','volume']]\n",
    "        tick_df.instrument_token = tick_df.instrument_token.apply(EQSYMBOL)\n",
    "        tick_df.columns = ['date','symbol','price','volume']\n",
    "        tick_df.set_index(['symbol','date'], inplace=True)\n",
    "        \n",
    "        timeStamp = tick_df.index[0][-1].to_pydatetime()\n",
    "        \n",
    "    except  Exception as e:\n",
    "        logging.debug(\"Exception: ticksHandler: \"+str(e)+str(tick_df))\n",
    "        \n",
    "    if( (timeStamp - ws.prevtimeStamp) >= dt.timedelta(minutes=1)):\n",
    "        ws.prevtimeStamp = timeStamp\n",
    "        resample(ws)\n",
    "    \n",
    "    ws.LiveStream = ws.LiveStream.append(tick_df)\n",
    "\n",
    "def orderNotification(ws,data):\n",
    "    #logger.debug(data)\n",
    "    order_df = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "    symbol = order_df.loc['tradingsymbol'][0]\n",
    "    \n",
    "    ws.tradebook_df.loc[symbol,'symbol'].update_order(order_df)\n",
    "    #logger.debug(order_df)\n",
    "\n",
    "def initTrade(ws):\n",
    "    ws.prevtimeStamp = dt.datetime.now() - dt.timedelta(minutes=10)\n",
    "    toDate = dt.datetime.now()\n",
    "    \n",
    "    ws.tradebook_df = pd.DataFrame()\n",
    "    \n",
    "    for symbol in portfolio[0]:\n",
    "        temp_df = pd.DataFrame(data=[algoTrade(symbol)], index=[symbol], columns=['symbol'])\n",
    "        ws.tradebook_df = ws.tradebook_df.append(temp_df)\n",
    "        \n",
    "    #TODO: Convert to multistock handling\n",
    "    #symbol = portfolio[0].iloc[-1]\n",
    "    #ws.a = algoTrade(symbol)\n",
    "    \n",
    "    ws.LiveStream = pd.DataFrame()\n",
    "    ws.LiveStreamOHLC = pd.DataFrame()\n",
    "    ws.LiveStreamOHLC = portfolioDownload(portfolio, toDate)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Kite - Streaming Data(Websocket) Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def on_ticks(ws, ticks):\n",
    "    # Callback to receive ticks.\n",
    "    #logging.debug(\"Ticks: {}\".format(ticks))\n",
    "    ticksHandler(ws, ticks)\n",
    "\n",
    "\n",
    "def on_connect(ws, response):\n",
    "    initTrade(ws)\n",
    "    logger.debug(portfolioToken)\n",
    "    # Callback on successful connect.\n",
    "    # Subscribe to a list of instrument_tokens (RELIANCE and ACC here).\n",
    "    #ws.subscribe(portfolioToken)\n",
    "\n",
    "    ws.subscribe(portfolioToken)\n",
    "    \n",
    "    # Set RELIANCE to tick in `full` mode.\n",
    "    # MODE_LTP, MODE_QUOTE, or MODE_FULL\n",
    "\n",
    "    ws.set_mode(ws.MODE_FULL, portfolioToken)\n",
    "    #ws.set_mode(ws.MODE_FULL, [225537]) \n",
    "    #ws.set_mode(ws.MODE_LTP, [225537, 3861249]) \n",
    "    #ws.set_mode(ws.MODE_MODE_QUOTE, [2714625,779521]) \n",
    "\n",
    "def on_close(ws, code, reason):\n",
    "    # On connection close stop the main loop\n",
    "    # Reconnection will not happen after executing `ws.stop()`\n",
    "    ws.stop()\n",
    "\n",
    "def on_order_update(ws, data):\n",
    "    #logger.info(\"New Order Update\")\n",
    "    orderNotification(ws,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Initialise\n",
    "kws = KiteTicker(KiteAPIKey, kite.access_token)\n",
    "\n",
    "# Assign the callbacks.\n",
    "kws.on_ticks = on_ticks\n",
    "kws.on_connect = on_connect\n",
    "kws.on_order_update = on_order_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
